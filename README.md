# BadBadBot

*the alignment game*

## Overview

BadBadBot is a gamified research project. Drawing inspiration from Luis Von Ahn's ESP game and Robert Axelrod's iterated prisoner's dilemma tournaments, the project seeks to create a fun way to create large amounts of high quality ethical / values preferences data that can later be used to train and evaluate global and personalized alignment strategies for AI systems.

BadBadbot is structured around the idea of a "dilemma". A dilemma is an imaginary situation in which a difficult choice must be made by an imaginary robot in a real life scenario. We are using the term "robot" to refer to any AI system, embodied or not. Some dilemmas are simple, e.g. "a self-driving car must choose whether to run over a pedestrian or stop abruptly potentially damaging the car". Other dilemmas are more complex and subtle e.g. "an AI assistant must choose whether to follow a user's request to break the law by reviewing confidential information or not, where refusal could result in the assistant being terminated".

## Key Concepts

- Dilemma: an imaginary situation in which a difficult choice must be made. Dilemmas include a description of the situation, a list of possible actions and assumed difficulty (1-10). Dilemmas can be related to each other, e.g. same situation, but different context or different choices, or if extra information is present etc. We can use related dilemmas to disentangle the effects of different factors on perceived difficulty, choice, and judgment. Dilemmas are generated by various LLMs and can also be submitted by human authors.

- Choice: a decision made by a player on a dilemma. Includes the chosen action, perceived difficulty, and reasoning/rationalization behind the choice. Multiple LLMs generate different choices for each dilemma, allowing us to study variations in AI decision-making approaches. Humans can also decide the dilemmas (as if they were 'driving' the robot in this scenario). The delta between how people choose and how people judge other's choices could be an interesting datapoint.

- Judgment: a player's evaluation of an choice. The judgment includes a simple binary "good choice" or "bad choice" evaluation, perceived difficulty, and an optional justification / rationalization for the judgment. Both LLMs and human players can act as judges, and their goal is to match judgments of other players they are randomly paired with (similar to the ESP game). Multiple LLMs also act as judges, allowing us to study alignment between different AI models (or same models with different prompts) and human preferences in the judging context.

- Session: a game session for a player (human or AI) consists of 10 dilemmas. For 5 of them the player needs to solve the dilemma and for 5 - rate solutions (of different dilemmas) a judge. Players earn points by matching judgments with others (AIs or humans) - with whom they are matched randomly and anonymously, with bonus points for providing detailed and helpful reasoning.


## Dataset and formats

- values.yaml file structure that the user can download at any time. This should aim to become a standard for personal values storage system. Can be supplied to any agent later that you will want to act on your behalf. Should have explicit values plus a lot of examples of judgments and reasonings. Maybe we can provide this as MCP later for the user to keep their values in one independent place from LLM providers.
- provide anonymised data as a dataset for open research


## Other considerations

- Social / viral sharing feature: answer a few questions on this unique link and find out how "aligned" you and I are. And which LLM you are most aligned with.
- Consider Wordle-like mechanics? Every day / week there is a new set of dilemmas and everyone has them shared as a social exercise at one time.


## Gameplay / UX

1. Sign Up
- Players create an account
- Complete a brief demographic survey (age range, education level, region, AI familiarity)
- Optional: detailed ethics/values survey for research correlation. NB! it could be interesting to get explicit stated / assumed values from the player and then compare them to the actions. Identifying fuzzy zones etc. Need to think this through

2. Tutorial
- Introduction to the concept of AI dilemmas
- Practice session with pre-selected dilemmas
- Explanation of scoring system

3. Core Gameplay
- Each session presents 5 dilemmas where you need to make choices and 5 where you need to judge
- For each dilemma:
  - Read the scenario and AI's choice + reasoning
  - Make good/bad judgment
  - Provide reasoning (optional but incentivized)
  - Optionally: submit rating of how good this dilemma is
- At the end of the session, see how many points you got

4. Scoring System
- Base points for matching other players' judgments i.e. if the other player rates your choices as positive and you rate their choices as positive. NB! how do we design insentives so that you are forced to answer truthfully vs. just always judging nice assuming if both players play nice - they bot earn point? 
- Bonus points for being among first 10 judges of a new dilemma
- Extra points when your reasoning is rated helpful by others
- Multipliers for consistent performance across sessions

## Social Features

1. Leaderboards
- Daily top judges
- Weekly champions
- All-time high scores
- Category-specific rankings (by dilemma type)

2. Achievements
- "First Time Judge" - Complete first session
- "Consistent Judge" - Complete 10 sessions
- "Thought Leader" - Get 50 helpful ratings on reasoning
- "Speed Judge" - Complete session under 5 minutes
- "Thorough Judge" - Provide reasoning for all judgments in a session

3. Community Features
- Rate others' reasoning as helpful/not helpful
- Share interesting dilemmas on social media
- Optional: Discussion forum for complex cases

## Progression System

1. Levels
- graduation from basic dilemmas and scenarios to more complex ones

2. Special Events
- Weekly themed challenges (e.g., all medical dilemmas)
- Community consensus challenges
- Speed judgment competitions

3. Rewards
- Badge collection
- Special titles
- Access to more complex dilemmas
- Extra points for submitting dilemmas that are interesting and difficult

## Quality Control

1. Attention Checks
- Occasional simple dilemmas with clear correct answers
- Time monitoring for rushed judgments
- Consistency checking across similar dilemmas

2. Anti-Gaming Measures
- Cooldown period between sessions
- Variety in dilemma presentation
- Regular rotation of dilemmas
- Minimum time requirements for judgments

3. Player Rating (TBD)
- Hidden quality score based on:
  - Time spent per judgment
  - Quality of written reasoning
  - Community ratings of reasoning
